{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 范式，减少过拟合\n",
    "* bias和variance，high bias表示欠拟合，high variance表示过拟合（缺数据），并且要以贝叶斯误差为基准，如下图所示，贝叶斯误差为0\n",
    "    <img src='../images/deeplearning/bias和variance.png' width='450px'>\n",
    "* 算法调试基本原则：<img src='../images/deeplearning/算法调试原则.png' width='400px'>\n",
    "* $L_2$范式，或者弗罗贝尼乌斯范数：减少high variance（过拟合），实际操作过程如下\n",
    "    * 前向传播：$J(W, b) = \\frac{1}{m}\\sum^m_{i=1}L(\\sigma(\\hat{y}), y) + \\frac{\\lambda}{2m}\\sum^L_{j=1}\\|W^{[L]}\\|^2_F$，其中$\\|W^{[L]}\\|^2_F=W^{[L]} \\bullet {W^{[L]}}^T$\n",
    "    * 反向传播：$\\partial W^{[L]}=\\frac{1}{m}\\partial Z^{[L]} \\bullet A^{[L-1]} + \\frac{\\lambda}{m}W^{[L]}$\n",
    "    * 这个步骤也叫做权重衰减，$L_2$范式让$W$的更新每次更加减少了$\\frac{\\alpha \\lambda}{m}$，也就是参数的更新由以前的$W'=W-\\alpha \\partial W$变为了$W'=(1-\\frac{\\alpha \\lambda}{m})W - \\alpha \\partial W$，可以确保代价函数的值是随着迭代次数逐步递减的，因为每次$W$的更新无论如何都要变小\n",
    "    * 加入$L_2$范式可以减少high variance（过拟合）的原因是当$\\lambda$设置成很大时，$W$的影响就会趋于0，会把很多隐藏层的功能抵消，将深度网络简化成一个简单的神经网络，甚至简化变成本身的机器学习模型；当$\\lambda$设置成很小时，$W$的影响就会趋于1，就是原本的深度网络模型；因此在这个调整过程中，总会有一个$\\lambda$的值让模型结果既不会high bias（欠拟合），也不会high variance（过拟合）\n",
    "    * $\\lambda$设置成很大时，$W$的影响就会趋于0的原因可能是由于公式$W'=(1-\\frac{\\alpha \\lambda}{m})W - \\alpha \\partial W$\n",
    "    * 上式中的$\\lambda$叫做正则化参数，$\\alpha$叫做衰减速率，描述梯度下降的速率\n",
    "* drop-out范式，对每层节点设计一个随机的drop概率参数，随机丢掉某些节点的结果，以此减少high variance（过拟合）\n",
    "    * 前向传播：$A^{[L]}_{new} = A^{[L]} \\ast D^{[L]}, A^{[L]}_{new} = \\frac{A^{[L]}_{new}}{D^{[L]}}$，$D^{[L]}$和$A^{[L]}$是同一纬度的矩阵，是按照drop-out概率生成的随机0和1元素矩阵，0表示过滤，1表示保留，并且每层网络这个drop-out概率不一样；这两个矩阵相乘是元素相乘，也就是每个元素乘以它对应的那个元素，例如$a_1 \\ast d_1$就是新的第一个元素的值；\n",
    "    * 反向传播：$\\partial A^{[L]}_{new} = \\partial A^{[L]} \\ast D^{[L]}, \\partial A^{[L]}_{new} = \\frac{\\partial A^{[L]}_{new}}{D^{[L]}}$\n",
    "    * 有点是用在训练数据比较少的领域，可以很好的减少high variance（过拟合），例如计算机视觉\n",
    "    * 但是加上drop-out后，代价函数的值就变得不可靠了，每次的结果都会发生很大的变化，不一定是个递减函数了\n",
    "* 其他范式，减少high variance（过拟合）\n",
    "    * 数据集扩增(Data augmentation)：随机扭转原始图片、放大截取、加波纹等等，让原始图片稍微变型作为新的数据集\n",
    "    * early-stop：就是通过观察代价函数的曲线，观察训练集和dev集的结果，出现分叉处就把迭代次数定位到分叉点，非常不好，把正交化搞混了，有在做结果调优，有在避免过拟合，这两个是分开的步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 归一化原始数据，加速模型训练\n",
    "* 归一化处理步骤：\n",
    "    * 首先求出训练集的中每个变量的平均值，然后减去该平均值，公式：$\\mu=\\frac{1}{m}\\sum^m_1 x^i, x^i=[x^i_1, x^i_2, \\cdots, x^i_n]^T, \\mu=[\\mu_1, \\mu_2, \\cdots, \\mu_n]^T, x^i=x^i-\\mu$\n",
    "    * 其次将第一步处理完的$x^i$进行方差处理，公式：$\\sigma^2=\\frac{1}{m}\\sum^m_1 {x^i}^2, \\sigma^2=[{\\sigma_1}^2, {\\sigma_2}^2, \\cdots, {\\sigma_n}^2]^T, x^i=\\frac{x^i}{\\sigma}$\n",
    "    * 综上两步，其实是对每个训练集的每个变量做如下处理：$x_i=\\frac{x_i-\\mu_i}{{\\sigma_i}^2}$，其中$\\mu_i$是$x_i$的期望，${\\sigma_i}^2$是$x_i$方差，下图演示了经过两步处理后的数据集变化：\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td><img src='..\\images\\deeplearning\\归一化处理数据集2维.png'></td>\n",
    "            <td><img src='..\\images\\deeplearning\\归一化处理数据集3维.png'></td>\n",
    "        </tr>\n",
    "    </table>\n",
    "    * 当归一化原始数据集时，需要保证训练集，测试集都是使用同一个$\\mu$和${\\sigma}^2$，所以最好求全部数据集的$\\mu$和${\\sigma}^2$，然后分别应用到训练集和测试集中，即使$\\mu$和${\\sigma}^2$是按训练集的数据求解，也要将其应用到训练集中。所以不要分别对训练集和测试集求解一对$\\mu$和${\\sigma}^2$\n",
    "* 梯度消失和梯度爆炸：\n",
    "    * 深度网络中，由于层数太多，导致代价函数的斜率可能会非常小（梯度消失），也可能非常大（梯度爆炸），随机初始化$w=\\frac{1}{n}$可以部分解决这个问题，$n$是训练集中变量（特征数）的数量，更多随机初始化$w$的方法可以参考《deep-neural-network》-《01_practical-aspects-of-deep-learning》-《03_setting-up-your-optimization-problem》-《03_weight-initialization-for-deep-networks.mp4》"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
