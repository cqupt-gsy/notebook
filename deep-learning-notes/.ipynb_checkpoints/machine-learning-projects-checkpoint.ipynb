{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orthogonalization正交互调整参数，一次只调节一个参数，判断先解决欠拟合还是过拟合\n",
    "* 策略：\n",
    "    * 先设立一个单一的指标矩阵，用来判断算法是否变得更好了\n",
    "    * 确立训练目标，慎重选择数据集的分布\n",
    "    * 合理选择不同数据集的大小\n",
    "    * 理性判断你的指标矩阵，当出现于人为判断不一致的情况下，要么更换该矩阵，要么给异常点加权值\n",
    "* 相关性能指标评价系统的好坏：假阳性，预测为真实际为假；假阴性，预测为假实际为真\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td><img src='../images/deeplearning/正确率和召回率.png'></td>\n",
    "            <td><img src='../images/deeplearning/F1Score.png'></td>\n",
    "        </tr>\n",
    "    </table>\n",
    "* 当性能参数很多时，设置一个优势列，其他都设为满足列，优势列意味着越大越好，满足列意味着达到某一阈值就不考虑了\n",
    "* 训练集，开发集，测试集的数据一定要来自同一个分布区域，将所有的数据随机打乱并从中选择对应的训练集，开发集，测试集\n",
    "* 训练集大小分布：<img src='../images/deeplearning/训练集大小分布.png' width='350px'>\n",
    "* 欠拟合和过拟合判断：（训练集，开发集，测试集使用同一分布的数据源）\n",
    "    * Human - level error – proxy for Bayes error\n",
    "    * If the difference between human-level error and the training error <b>(avoidable bias)</b> is bigger than the difference between the training error and the development error. The focus should be on bias reduction technique\n",
    "    * If the difference between training error and the development error <b>(variance)</b> is bigger than the difference between the human-level error and the training error. The focus should be on variance reduction technique\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td><img src='../images/deeplearning/欠拟合和过拟合判断示例.png'></td>\n",
    "            <td><img src='../images/deeplearning/欠拟合和过拟合判断总结.png'></td>\n",
    "        </tr>\n",
    "    </table>\n",
    "* 欠拟合和过拟合判断：（训练集与开发集和测试集使用不同分布的数据源）\n",
    "    * 欠拟合，过拟合问题同训练集判断一致，只是数据集是从训练集中分出来的一部分\n",
    "    * 数据缺失问题，是由训练集的数据分布和开发集不一样所产生（尽量构造出和开发集相同分布的训练集）\n",
    "    * 开发集过拟合问题，也就是开发集的结果太好，测试集的结果太差，表示真的开发集过多的优化\n",
    "    <img src='../images/deeplearning/欠拟合和过拟合和数据缺失判断总结.png' width='300px'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 错误分析，判断哪个改进点是下一步的重点\n",
    "* 分析dev集中出错的数据，快速通过表格的形式验证你的改进想法是否行得通，也就是说假如有100个错，然后其中有5个把狗的图像识别成了猫的图像，也就说你把这些错全部解决，也只是把正确率提高了0.5%，但是如果有一半都是这个原因引起的错，那么可以将正确率提高5%，这个例子要说明的是，你觉得那些地方可以改进，进去看错误数据类有多少符合你改进的思路，占比越大的越值得先改进（每一次改进可能就需要花费好几个月的时间）\n",
    "* 做一个全新的机器学习项目，基本思路就是做一个非常简单的模型，然后通过错误分析，和过拟合欠拟合分析决定下一步优化点，然后逐步优化模型，不要一上来就搞一个很复杂的模型\n",
    "* 训练集和开发集以及测试集的选择，一定要记住开发集和测试集是你模型的目标，所以这部分数据一定要使用真实数据，如果数据不够，也要保证这两个集合的数据都是真实数据，多的部分就混合到训练集中\n",
    "* transfer-learning（也就是在某个领域有很多数据可以将模型训练好，但是类似该领域的某领域数据很少，可以在通用领域的模型基础上训练这个特定领域的模型）：也就是说先用一些数据训练好了一个模型，例如猫图片识别；然后利用这个模型的部分参数来训练一个新的图像识别，例如狗图片识别。 fine-tuning，使用部分模型的参数（该训练原模型的最后几层）来训练新的数据集；pre-training，只使用模型的网络结构，模型所有参数都全部重新训练\n",
    "    * Task A and B have the same input 𝑥\n",
    "    * A lot more data for Task A than Task B\n",
    "    * Low level features from Task A could be helpful for Task B\n",
    "* multi-task-learning：输出层有多个节点，跟多分类的不同是，多分类计算最后一层多个节点的概率以判断属于哪一类，多任务学习的最后一层多个节点表示该结果包含多个元素，例如一张图片包含人行道，红绿色，停止标志等等，也就是训练集针对一个图片会有多个标签，所以最后一层多个节点对应某个标签是否在该图片中出现\n",
    "    * Training on a set of tasks that could benefit from having shared lower-level features\n",
    "    * Usually: Amount of data you have for each task is quite similar，共享不同任务之间的数据\n",
    "    * Can train a big enough neural network to do well on all tasks，一个网络解决多个问题效率高\n",
    "* Data augmentation：数据如果少了，就用镜像，改变色差，随机截取图片等方式增加训练数据"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
